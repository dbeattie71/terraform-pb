syntax "proto3";

package google;

message GoogleBigqueryDataTransferConfig {

  // The number of days to look back to automatically refresh the data.
For example, if dataRefreshWindowDays = 10, then every day BigQuery
reingests data for [today-10, today-1], rather than ingesting data for
just [today-1]. Only valid if the data source supports the feature.
Set the value to 0 to use the default value.
  data_refresh_window_days = 1;

  // The data source id. Cannot be changed once the transfer config is created.
  data_source_id = 2;

  // The BigQuery target dataset id.
  destination_dataset_id = 3;

  // When set to true, no runs are scheduled for a given transfer.
  disabled = 4;

  // The user specified display name for the transfer config.
  display_name = 5;
  id = 6;

  // The geographic location where the transfer config should reside.
Examples: US, EU, asia-northeast1. The default value is US.
  location = 7;

  // The resource name of the transfer config. Transfer config names have the
form projects/{projectId}/locations/{location}/transferConfigs/{configId}.
Where configId is usually a uuid, but this is not required.
The name is ignored when creating a transfer config.
  name = 8;

  // These parameters are specific to each data source.
  params = 9;
  project = 10;

  // Data transfer schedule. If the data source does not support a custom
schedule, this should be empty. If it is empty, the default value for
the data source will be used. The specified times are in UTC. Examples
of valid format: 1st,3rd monday of month 15:30, every wed,fri of jan,
jun 13:15, and first sunday of quarter 00:00. See more explanation
about the format here:
https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format
NOTE: the granularity should be at least 8 hours, or less frequent.
  schedule = 11;
  message Timeouts {
    create = 1;
    delete = 2;
    update = 3;
  }
  timeouts = 12;
}