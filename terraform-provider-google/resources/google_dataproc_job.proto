syntax="proto3";

package google;

message GoogleDataprocJob {

  // Output-only. If present, the location of miscellaneous control files which may be used as part of job setup and handling. If not present, control files may be placed in the same location as driver_output_uri.
  string driver_controls_files_uri = 1;

  // Output-only. A URI pointing to the location of the stdout of the job's driver program
  string driver_output_resource_uri = 2;
  bool   force_delete = 3;
  string id = 4;

  // Optional. The labels to associate with this job.
  map<string, string> labels = 5;
  string project = 6;
  string region = 7;
  message Status {
    string details = 1;
    string state = 2;
    string state_start_time = 3;
    string substate = 4;
  }
  repeated Status status = 8;
  message HadoopConfig {
    repeated string archive_uris = 1;
    repeated string args = 2;
    repeated string file_uris = 3;
    repeated string jar_file_uris = 4;
    string main_class = 5;
    string main_jar_file_uri = 6;
    map<string, string> properties = 7;
    message LoggingConfig {

      // Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.
      map<string, string> driver_log_levels = 1;
    }
    repeated LoggingConfig logging_config = 8;
  }
  repeated HadoopConfig hadoop_config = 9;
  message HiveConfig {
    bool   continue_on_failure = 1;
    repeated string jar_file_uris = 2;
    map<string, string> properties = 3;
    string query_file_uri = 4;
    repeated string query_list = 5;
    map<string, string> script_variables = 6;
  }
  repeated HiveConfig hive_config = 10;
  message PigConfig {
    bool   continue_on_failure = 1;
    repeated string jar_file_uris = 2;
    map<string, string> properties = 3;
    string query_file_uri = 4;
    repeated string query_list = 5;
    map<string, string> script_variables = 6;
    message LoggingConfig {

      // Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.
      map<string, string> driver_log_levels = 1;
    }
    repeated LoggingConfig logging_config = 7;
  }
  repeated PigConfig pig_config = 11;
  message Placement {

    // The name of the cluster where the job will be submitted
    string cluster_name = 1;

    // Output-only. A cluster UUID generated by the Cloud Dataproc service when the job is submitted
    string cluster_uuid = 2;
  }
  repeated Placement placement = 12;
  message PysparkConfig {

    // Optional. HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip
    repeated string archive_uris = 1;

    // Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission
    repeated string args = 2;

    // Optional. HCFS URIs of files to be copied to the working directory of Python drivers and distributed tasks. Useful for naively parallel tasks
    repeated string file_uris = 3;

    // Optional. HCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks
    repeated string jar_file_uris = 4;

    // Required. The HCFS URI of the main Python file to use as the driver. Must be a .py file
    string main_python_file_uri = 5;

    // Optional. A mapping of property names to values, used to configure PySpark. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code
    map<string, string> properties = 6;

    // Optional. HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip
    repeated string python_file_uris = 7;
    message LoggingConfig {

      // Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.
      map<string, string> driver_log_levels = 1;
    }
    repeated LoggingConfig logging_config = 8;
  }
  repeated PysparkConfig pyspark_config = 13;
  message Reference {

    // The job ID, which must be unique within the project. The job ID is generated by the server upon job submission or provided by the user as a means to perform retries without creating duplicate jobs
    string job_id = 1;
  }
  repeated Reference reference = 14;
  message Scheduling {

    // Maximum number of times per hour a driver may be restarted as a result of driver terminating with non-zero code before job is reported failed.
    int64  max_failures_per_hour = 1;
  }
  repeated Scheduling scheduling = 15;
  message SparkConfig {
    repeated string archive_uris = 1;
    repeated string args = 2;
    repeated string file_uris = 3;
    repeated string jar_file_uris = 4;
    string main_class = 5;
    string main_jar_file_uri = 6;
    map<string, string> properties = 7;
    message LoggingConfig {

      // Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.
      map<string, string> driver_log_levels = 1;
    }
    repeated LoggingConfig logging_config = 8;
  }
  repeated SparkConfig spark_config = 16;
  message SparksqlConfig {
    repeated string jar_file_uris = 1;
    map<string, string> properties = 2;
    string query_file_uri = 3;
    repeated string query_list = 4;
    map<string, string> script_variables = 5;
    message LoggingConfig {

      // Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.
      map<string, string> driver_log_levels = 1;
    }
    repeated LoggingConfig logging_config = 6;
  }
  repeated SparksqlConfig sparksql_config = 17;
  message Timeouts {
    string create = 1;
    string delete = 2;
  }
  Timeouts timeouts = 18;
}